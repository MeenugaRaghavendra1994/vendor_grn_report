import streamlit as st
import pandas as pd
from google.cloud import bigquery
from datetime import datetime
from google.oauth2 import service_account
import streamlit as st

# ================= CONFIG =================
PROJECT_ID = "grnreport181922"
DATASET = "vendor_grn"
MAIN_TABLE = "vendor_grn_data"
TEMP_TABLE = "temp_vendor_grn"

credentials = service_account.Credentials.from_service_account_info(
    st.secrets["gcp_service_account"]
)

client = bigquery.Client(
    credentials=credentials,
    project=st.secrets["gcp_service_account"]["project_id"],
)

# ================= STREAMLIT UI =================
st.set_page_config(page_title="Vendor GRN Upload", layout="wide")
st.title("ðŸ“¦ Vendor GRN Data Upload & Visibility")

uploaded_file = st.file_uploader("Upload Excel File", type=["xlsx"])

# ================= COLUMN MAPPING =================
REQUIRED_COLUMNS = [
    "Vendor Name", "PO Number", "Reference No", "SKU", "Name",
    "Invoice Qty", "Received Qty", "Short Excess Qty", "Damage Qty",
    "Actual GRN Qty", "Warehouse", "Status", "GRN No",
    "Ekart GRN Qty", "Makali GRN Qty",
    "K12 to SSPL PO", "K12 to SSPL GRN",
    "STO Qty", "PO", "Out Bound", "Bill", "GRN"
]

QTY_COLUMNS = [
    "Invoice Qty", "Received Qty", "Short Excess Qty", "Damage Qty",
    "Actual GRN Qty", "Ekart GRN Qty", "Makali GRN Qty", "STO Qty"
]

# ================= FUNCTIONS =================
def validate_columns(df):
    missing = set(REQUIRED_COLUMNS) - set(df.columns)
    if missing:
        st.error(f"Missing columns: {missing}")
        st.stop()

def preprocess(df):
    df = df[REQUIRED_COLUMNS]
    df[QTY_COLUMNS] = df[QTY_COLUMNS].fillna(0).astype(int)

    grouped = (
        df.groupby(["Reference No", "SKU"], as_index=False)
        .agg({
            **{col: "sum" for col in QTY_COLUMNS},
            "Vendor Name": "first",
            "PO Number": "first",
            "Name": "first",
            "WH": "first",
            "Status": "first",
            "GRN No": "first",
            "K12 to SSPL PO": "first",
            "K12 to SSPL GRN": "first",
            "PO": "first",
            "Out Bound": "first",
            "Bill": "first",
            "GRN": "first"
        })
    )

    grouped["last_updated"] = datetime.utcnow()
    return grouped

def load_temp_table(df):
    table_id = f"{PROJECT_ID}.{DATASET}.{TEMP_TABLE}"
    job = client.load_table_from_dataframe(
        df,
        table_id,
        job_config=bigquery.LoadJobConfig(write_disposition="WRITE_TRUNCATE")
    )
    job.result()

def merge_to_main():
    merge_sql = f"""
    MERGE `{PROJECT_ID}.{DATASET}.{MAIN_TABLE}` T
    USING `{PROJECT_ID}.{DATASET}.{TEMP_TABLE}` S
    ON T.Reference_No = S.Reference_No
       AND T.SKU = S.SKU

    WHEN MATCHED THEN UPDATE SET
      T.Invoice_Qty = T.Invoice_Qty + S.Invoice_Qty,
      T.Received_Qty = T.Received_Qty + S.Received_Qty,
      T.Short_Excess_Qty = T.Short_Excess_Qty + S.Short_Excess_Qty,
      T.Damage_Qty = T.Damage_Qty + S.Damage_Qty,
      T.Actual_GRN_Qty = T.Actual_GRN_Qty + S.Actual_GRN_Qty,
      T.Ekart_GRN_Qty = T.Ekart_GRN_Qty + S.Ekart_GRN_Qty,
      T.Makali_GRN_Qty = T.Makali_GRN_Qty + S.Makali_GRN_Qty,
      T.STO_Qty = T.STO_Qty + S.STO_Qty,
      T.last_updated = CURRENT_TIMESTAMP()

    WHEN NOT MATCHED THEN
      INSERT ROW
    """
    client.query(merge_sql).result()

# ================= MAIN FLOW =================
if uploaded_file:
    df = pd.read_excel(uploaded_file)
    validate_columns(df)

    st.subheader("ðŸ“„ Raw Data Preview")
    st.dataframe(df)

    df_processed = preprocess(df)

    st.subheader("ðŸ“Š Grouped (Reference No + SKU)")
    st.dataframe(df_processed)

    if st.button("âœ… Save to BigQuery"):
        load_temp_table(df_processed)
        merge_to_main()
        st.success("Data successfully merged into BigQuery!")

# ================= VISIBILITY =================
st.subheader("ðŸ“ˆ BigQuery Live Data")

query = f"""
SELECT
  Reference_No,
  SKU,
  Invoice_Qty,
  Received_Qty,
  Actual_GRN_Qty,
  last_updated
FROM `{PROJECT_ID}.{DATASET}.{MAIN_TABLE}`
ORDER BY last_updated DESC
"""

result_df = client.query(query).to_dataframe()
st.dataframe(result_df)
